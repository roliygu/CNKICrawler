# CNKICrawler

---

[WIP]

## 一. 简介

适应最新版的cnki界面。checkout一个新的分支,采用新的库实现cnki的爬虫。

## 二. 依赖

1. python27
2. scrapy
3. requests
4. BeautifulSoup4

依赖及其具体版本将由virtual env控制,可以不用关心。

## 三. 使用方法

### 0. pip

请确认已经安装好pip,并能正常使用

### 1. 初始化运行环境

为了避免依赖包版本带来的不兼容问题,本项目使用了`virtual env`来管理Python运行环境。
```
# 在项目根目录下
make setup
```
将会下载安装`virtual env`,并在virtualenv中安装本项目所有依赖的python包。
初始化完成后,以后运行不需要重复初始化。

### 2. 进入virtual env

如果上一步成功后,就能看见`./cnki_spider`目录

```
# 在项目根目录下
source cnki_spider/bin/activate
```
执行本命令后,当前终端就进入virtual env环境,之后用到的python命令,将自动指向virtual env中的python。

### 3. 运行测试

确保已经在virtual env内,如在终端的主机名前看到`(cnki_spider)`前缀。

```
# 在项目根目录下
make test
```

### 4. 运行爬虫

确保在virtual env内,且之前的测试没有问题。
```
# 在项目根目录下
make run
```

### 5. 其他命令

介绍一些其他非流程使用的命令
`make clean`, 将清理log和tmp
`deactivate`, 脱离当前virtual env,恢复到本机原来的python环境

## 四. 爬取流程及注意事项

### 1. 

## 五. 开发中内容

### 1. bug

#### 1.1 单搜索标签限制总条数为6000条

当请求到概要列表时,可以拿到当前标签下的总文献数和概要列表的总页数。但是CNKI做了限制,概要列表数*每页详情数不能超过6000。
具体表现就是,当点击了某个标签的第一页概要后,发现尽管总条数有上百万条,但是总页数最大是120页,如果申请120之后的概要列表,则会返回空。最终导致,点击某个具体标签最多能请求到6000条记录。
修复方式:利用多级标签,比如按选择学科最细粒度的标签,再选择按年度划分,这样可以确保尽可能得覆盖所有论文。

### 2. feature

#### 2.1 论文详情页还有信息没有收集

目前论文详情页还只收集了摘要,关键词等信息。实际上还有论文引用关系,作者人际关系等数据没有抓取。